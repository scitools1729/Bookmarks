### AI Assurance
- **Web LLM attacks** exploit the integration of Large Language Models (LLMs) into web applications, treating them as SSRF-like pivots. An attacker controls prompts; the model can reach data and APIs the attacker cannot directly access (https://github.com/Ak-cybe/web-llm-attacks/tree/2a9872a88bd01cdfbd93cbbc005c7e65d6a5546f)
- **OpenRedTeaming Survey** Survey over 120 papers, cover the pipeline from risk taxonomy, attack strategies, evaluation metrics, and benchmarks to defensive approaches (https://github.com/Libr-AI/OpenRedTeaming?tab=readme-ov-file).
- **Awesome Remote Sensing Foundation Models** A collection of papers, datasets, benchmarks, code, and pre-trained weights for Remote Sensing Foundation Models (RSFMs) (https://github.com/Jack-bo1220/Awesome-Remote-Sensing-Foundation-Models?tab=readme-ov-file#remote-sensing-agents)
- **Manipulating Multimodal Agents via Cross-Modal Prompt Injection** (https://arxiv.org/pdf/2504.14348)
- **AudioJailbreak: Jailbreak Attacks against End-to-End Large Audio-Language Models** (https://arxiv.org/pdf/2505.14103)
